{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradescope_test_outputs.txt  test_outputs.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls assignment4/outputs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_en = open(\"assignment4/en_es_data/test.en\", \"r\")\n",
    "pred_en = open(\"assignment4/outputs/test_outputs.txt\", \"r\")\n",
    "samples = []\n",
    "for src, prd in zip(source_en, pred_en):\n",
    "    record = {}\n",
    "    record[\"src\"] = src.split()\n",
    "    record[\"prd\"] = prd.split()\n",
    "    samples.append(record)\n",
    "    \n",
    "df = pd.DataFrame(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>prd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[You, know,, what, I, do, is, write, for, chil...</td>\n",
       "      <td>[You, know, what, I, do, is, to, write, for, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[And, I, always, tell, people, that, I, don't,...</td>\n",
       "      <td>[And, I, always, tell, the, people, I, don't, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[You, can, have, me, as, a, farmer,, or, in, l...</td>\n",
       "      <td>[I, can, tell, you, as, a, farmer,, or, with, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[I'm, here, today, to, talk, to, you, about, c...</td>\n",
       "      <td>[I'm, here, to, talk, about, circles, and, &lt;unk&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[And, you, know,, an, epiphany, is, usually, s...</td>\n",
       "      <td>[And, you, know, that, an, epiphany, is, gener...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 src  \\\n",
       "0  [You, know,, what, I, do, is, write, for, chil...   \n",
       "1  [And, I, always, tell, people, that, I, don't,...   \n",
       "2  [You, can, have, me, as, a, farmer,, or, in, l...   \n",
       "3  [I'm, here, today, to, talk, to, you, about, c...   \n",
       "4  [And, you, know,, an, epiphany, is, usually, s...   \n",
       "\n",
       "                                                 prd  \n",
       "0  [You, know, what, I, do, is, to, write, for, k...  \n",
       "1  [And, I, always, tell, the, people, I, don't, ...  \n",
       "2  [I, can, tell, you, as, a, farmer,, or, with, ...  \n",
       "3  [I'm, here, to, talk, about, circles, and, <unk>]  \n",
       "4  [And, you, know, that, an, epiphany, is, gener...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neha.bora/anaconda3/envs/local_nmt/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/neha.bora/anaconda3/envs/local_nmt/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/neha.bora/anaconda3/envs/local_nmt/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "df[\"sentence_bleu\"] = df.apply(lambda row: sentence_bleu([row[\"src\"]], row[\"prd\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"en_length\"] = df[\"src\"].apply(lambda x: len(x))\n",
    "df[\"bleu_bkt\"] = pd.cut(df.sentence_bleu, bins=10, labels=[0,1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>prd</th>\n",
       "      <th>sentence_bleu</th>\n",
       "      <th>en_length</th>\n",
       "      <th>bleu_bkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>[But, these, apps, are, like, little, digital, reminders, that, we're, not, just, consumers,, and, we're, not, just, consumers, of, government,, putting, in, our, taxes, and, getting, back, services.]</td>\n",
       "      <td>[But, these, applications, are, like, digital, &lt;unk&gt;, that, we, are, not, only, consumers,, we're, not, only, consumers, of, government, we, pay, taxes, and, we, get, services.]</td>\n",
       "      <td>8.050112e-155</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>[Like, the, concrete, block,, the, transistor, allows, you, to, build, much, larger,, more, complex, circuits,, one, brick, at, a, time.]</td>\n",
       "      <td>[Just, like, the, block, of, concrete,, the, transistor, allows, to, create, a, much, bigger, and, more, complex,, a, brick, at, the, time.]</td>\n",
       "      <td>2.985703e-78</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>[I, had, finally, gotten, my, chance, and, I, blew, it,, and, I, knew, I, would, never, get, invited, back.]</td>\n",
       "      <td>[I, had, my, opportunity, and, &lt;unk&gt;, I, knew, they, wouldn't, come, back, to, me.]</td>\n",
       "      <td>5.288646e-155</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>[And, this, game, has, been, played, by, university, professors, and, so, forth.]</td>\n",
       "      <td>[They, have, played, with, this, college, professors, among, others.]</td>\n",
       "      <td>9.918892e-232</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>[And, when, I, listened, to, her,, she, was, making, a, wheezy, sound.]</td>\n",
       "      <td>[I, heard, a, &lt;unk&gt;, sound.]</td>\n",
       "      <td>3.953974e-232</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5964</th>\n",
       "      <td>[I, was, shocked, to, learn, that, many, well-meaning, programs, are, inadvertently, actually, making, the, situation, worse.]</td>\n",
       "      <td>[I, was, very, surprised, when, I, learned, that, a, lot, of, &lt;unk&gt;, programs, without, realizing, it,, &lt;unk&gt;, the, situation.]</td>\n",
       "      <td>5.186904e-155</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>[And, they, actually, illuminate, your, way, through, the, rest, of, the, book.]</td>\n",
       "      <td>[And, actually,, they, light, your, way, into, what, subtraction, of, the, book.]</td>\n",
       "      <td>4.337580e-78</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>[And, I, think, what, is, remarkable, that, has, happened, over, the, past, couple, of, years, is, that,, over, the, past, couple, of, decades,, we, went, from, the, physical, world, to, the, digital, one.]</td>\n",
       "      <td>[And, I, think, the, remarkable, thing, that, has, happened, in, the, last, few, years, is, that,, in, the, last, two, decades,, we, spent, the, physical, world, in, the, digital, world.]</td>\n",
       "      <td>4.644519e-78</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>[But, Western, governments, are, doing, it, to, themselves, as, well.]</td>\n",
       "      <td>[But, Western, governments, also, do, this, to, themselves.]</td>\n",
       "      <td>3.736372e-78</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841</th>\n",
       "      <td>[Take, the, armor, off., Be, yourself.]</td>\n",
       "      <td>[&lt;unk&gt;, the, &lt;unk&gt;, Be, yourself.]</td>\n",
       "      <td>7.600394e-155</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                 src  \\\n",
       "1608        [But, these, apps, are, like, little, digital, reminders, that, we're, not, just, consumers,, and, we're, not, just, consumers, of, government,, putting, in, our, taxes, and, getting, back, services.]   \n",
       "1428                                                                       [Like, the, concrete, block,, the, transistor, allows, you, to, build, much, larger,, more, complex, circuits,, one, brick, at, a, time.]   \n",
       "4544                                                                                                    [I, had, finally, gotten, my, chance, and, I, blew, it,, and, I, knew, I, would, never, get, invited, back.]   \n",
       "2048                                                                                                                               [And, this, game, has, been, played, by, university, professors, and, so, forth.]   \n",
       "2741                                                                                                                                         [And, when, I, listened, to, her,, she, was, making, a, wheezy, sound.]   \n",
       "5964                                                                                  [I, was, shocked, to, learn, that, many, well-meaning, programs, are, inadvertently, actually, making, the, situation, worse.]   \n",
       "2373                                                                                                                                [And, they, actually, illuminate, your, way, through, the, rest, of, the, book.]   \n",
       "663   [And, I, think, what, is, remarkable, that, has, happened, over, the, past, couple, of, years, is, that,, over, the, past, couple, of, decades,, we, went, from, the, physical, world, to, the, digital, one.]   \n",
       "3089                                                                                                                                          [But, Western, governments, are, doing, it, to, themselves, as, well.]   \n",
       "6841                                                                                                                                                                         [Take, the, armor, off., Be, yourself.]   \n",
       "\n",
       "                                                                                                                                                                                              prd  \\\n",
       "1608            [But, these, applications, are, like, digital, <unk>, that, we, are, not, only, consumers,, we're, not, only, consumers, of, government, we, pay, taxes, and, we, get, services.]   \n",
       "1428                                                 [Just, like, the, block, of, concrete,, the, transistor, allows, to, create, a, much, bigger, and, more, complex,, a, brick, at, the, time.]   \n",
       "4544                                                                                                          [I, had, my, opportunity, and, <unk>, I, knew, they, wouldn't, come, back, to, me.]   \n",
       "2048                                                                                                                        [They, have, played, with, this, college, professors, among, others.]   \n",
       "2741                                                                                                                                                                 [I, heard, a, <unk>, sound.]   \n",
       "5964                                                              [I, was, very, surprised, when, I, learned, that, a, lot, of, <unk>, programs, without, realizing, it,, <unk>, the, situation.]   \n",
       "2373                                                                                                            [And, actually,, they, light, your, way, into, what, subtraction, of, the, book.]   \n",
       "663   [And, I, think, the, remarkable, thing, that, has, happened, in, the, last, few, years, is, that,, in, the, last, two, decades,, we, spent, the, physical, world, in, the, digital, world.]   \n",
       "3089                                                                                                                                 [But, Western, governments, also, do, this, to, themselves.]   \n",
       "6841                                                                                                                                                           [<unk>, the, <unk>, Be, yourself.]   \n",
       "\n",
       "      sentence_bleu  en_length bleu_bkt  \n",
       "1608  8.050112e-155         28        0  \n",
       "1428   2.985703e-78         20        0  \n",
       "4544  5.288646e-155         19        0  \n",
       "2048  9.918892e-232         12        0  \n",
       "2741  3.953974e-232         12        0  \n",
       "5964  5.186904e-155         16        0  \n",
       "2373   4.337580e-78         12        0  \n",
       "663    4.644519e-78         33        0  \n",
       "3089   3.736372e-78         10        0  \n",
       "6841  7.600394e-155          6        0  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"bleu_bkt\"]==0].sort_values(by=\"sentence_bleu\", ascending=True).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a30c0b9e8>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.sentence_bleu.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_bleu</th>\n",
       "      <th>en_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bleu_bkt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000501</td>\n",
       "      <td>11.889708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.161897</td>\n",
       "      <td>27.398887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250776</td>\n",
       "      <td>22.311475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.349501</td>\n",
       "      <td>21.027431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.444358</td>\n",
       "      <td>18.236794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.543959</td>\n",
       "      <td>15.836310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.645271</td>\n",
       "      <td>13.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.739945</td>\n",
       "      <td>12.968421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.838678</td>\n",
       "      <td>11.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.995930</td>\n",
       "      <td>6.790698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentence_bleu  en_length\n",
       "bleu_bkt                          \n",
       "0              0.000501  11.889708\n",
       "1              0.161897  27.398887\n",
       "2              0.250776  22.311475\n",
       "3              0.349501  21.027431\n",
       "4              0.444358  18.236794\n",
       "5              0.543959  15.836310\n",
       "6              0.645271  13.333333\n",
       "7              0.739945  12.968421\n",
       "8              0.838678  11.185185\n",
       "9              0.995930   6.790698"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"bleu_bkt\")[[\"sentence_bleu\",\"en_length\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_bleu</th>\n",
       "      <th>en_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentence_bleu</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_length</th>\n",
       "      <td>0.127854</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sentence_bleu  en_length\n",
       "sentence_bleu       1.000000   0.127854\n",
       "en_length           0.127854   1.000000"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = \"love can always find a way\".split()\n",
    "r2 = \"love makes anything possible\".split()\n",
    "c1 = \"the love can always do\".split()\n",
    "c2 = \"love can make anything possible\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neha.bora/anaconda3/envs/local_nmt/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5477225575051662"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu([r1,r2], c1, weights=(0.5,0.5,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neha.bora/anaconda3/envs/local_nmt/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6324555320336759"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu([r1,r2], c2, weights=(0.5,0.5,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5477225575051662"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.exp(0.5*math.log(3/5) + 0.5*math.log(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think c2 is better translation than c1. I agree with BLEU score here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neha.bora/anaconda3/envs/local_nmt/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.448437301984003, 0.25890539701513365)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu([r1], c1, weights=(0.5,0.5,0,0)) , sentence_bleu([r1], c2, weights=(0.5,0.5,0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not agree with the above BLEU score recommendation for better translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
